<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Project 1: Hybrid Images</title>
    <!--<link href="./style.css" rel="stylesheet" type="text/css">-->
    <link rel="stylesheet" href="Project%201%20Hybrid%20Images_files/fonts.css">
    <link rel="stylesheet" href="Project%201%20Hybrid%20Images_files/normalize.css">
    <link rel="stylesheet" href="Project%201%20Hybrid%20Images_files/main.css">
    <link rel="stylesheet" href="Project%201%20Hybrid%20Images_files/jht.css">
<style type="text/css" media="all">
#primarycontent {
    margin-left: auto;  
    width: expression(document.body.clientWidth > 995? "995px": "auto" );
    margin-right: auto;
    text-align: left;
    max-width: 995px 
}
</style></head>



<body>
<div id="primarycontent">

<center>
<img src="Project%201%20Hybrid%20Images_files/hybrid_image.jpg" width="410" height="361">
<br>
<em>Look at the image from very close, then from far away.</em>
</center>

<h1> Project 1: Image Filtering and Hybrid Images<br>
<a href="https://cs.brown.edu/courses/csci1430/2017_Spring/">CSCI 1430: Introduction to Computer Vision</a>
</h1>

<h2>Brief</h2> 
<ul> 
  <li>Due: 9pm on Friday, 10th February 2017</li> 
  <li>Project materials including writeup template <a href="https://cs.brown.edu/courses/csci1430/2017_Spring/proj1a/proj1.zip">proj1.zip (1.9 MB)</a>.
  </li><li>Hand-in process: $ cs1430_handin proj1</li>
  <li>Required files: README, code/, html/, html/index.html</li>
</ul> 

<h2>Overview</h2>

<p>The goal of this assignment is to write an image filtering function and use it to create <a href="http://cvcl.mit.edu/hybrid_gallery/gallery.html">hybrid images</a> using a simplified version of the SIGGRAPH 2006 <a href="http://cvcl.mit.edu/publications/OlivaTorralb_Hybrid_Siggraph06.pdf">paper</a> by Oliva, Torralba, and Schyns.
<i>Hybrid images</i> are static images that change in interpretation as a
 function of the viewing distance.
The basic idea is that high frequency tends to dominate perception when 
it is available, but, at a distance, only the low frequency (smooth) 
part of the signal can be seen.
By blending the high frequency portion of one image with the 
low-frequency portion of another, you get a hybrid image that leads to 
different interpretations at different distances.
</p>
<br>


<h2>Details</h2>

<p>
This project is intended to familiarize you with MATLAB and image 
filtering. Once you have created an image filtering function, it is 
relatively straightforward to construct hybrid images. If you don't 
already have MATLAB, please install it from the <a href="https://www.brown.edu/information-technology/software/">Brown University Software Catalog</a>.
 During the installation process, please make sure to install the Image 
Processing Toolbox and the Computer Vision System Toolbox. MATLAB comes 
with a 'Getting Started with MATLAB' tutorial, which you can find in 
'Help', and you may also find this <a href="https://cs.brown.edu/courses/csci1430/2017_Spring/docs/matlab-tutorial/">tutorial on MATLAB</a> helpful.
</p><p>
<b>Image Filtering.</b> Image filtering (or convolution) is a 
fundamental image processing tool. See chapter 3.2 of Szeliski and the 
lecture materials to learn about image filtering (specifically linear 
filtering). MATLAB has numerous built in and efficient functions to 
perform image filtering, but you will be writing your own such function 
from scratch for this assignment. More specifically, you will implement <code>my_imfilter()</code> which imitates the default behavior of the build in <code>imfilter()</code> function. As specified in <code>my_imfilter.m</code>,
 your filtering algorithm must (1) support grayscale and color images 
(2) support arbitrary shaped filters, as long as both dimensions are odd
 (e.g. 7x9 filters but not 4x5 filters) (3) pad the input image with 
zeros or reflected image content and (4) return a filtered image which 
is the same resolution as the input image. We have provided a script, <code>proj1_test_filtering.m</code>, to help you debug your image filtering algorithm. 

</p><p>
<b>Hybrid Images.</b> A hybrid image is the sum of a low-pass filtered 
version of the one image and a high-pass filtered version of a second 
image. There is a free parameter, which can be tuned for each image 
pair, which controls <i>how much</i> high frequency to remove from the 
first image and how much low frequency to leave in the second image. 
This is called the "cutoff-frequency". In the paper it is suggested to 
use two cutoff frequencies (one tuned for each image) and you are free 
to try that, as well. In the starter code, the cutoff frequency is 
controlled by changing the standard deviation of the Gausian filter used
 in constructing the hybrid images.
</p><p>
We provide you with 5 pairs of aligned images which can be merged 
reasonably well into hybrid images. The alignment is important because 
it affects the perceptual grouping (read the paper for details). We 
encourage you to create additional examples (e.g. change of expression, 
morph between different objects, change over time, etc.). See the <a href="http://cvcl.mit.edu/hybrid_gallery/gallery.html">hybrid images project page</a> for some inspiration. The project page also contains materials from their <a href="http://cvcl.mit.edu/publications/publications.html">Siggraph presentation</a>.
</p><p>
For the example shown at the top of the page, the two original images look like this:
</p><p>
</p><center><img src="Project%201%20Hybrid%20Images_files/dog.jpg"><img src="Project%201%20Hybrid%20Images_files/cat.jpg"></center>
<p></p><p>
The low-pass (blurred) and high-pass versions of these images look like this:
</p><p>
</p><center><img src="Project%201%20Hybrid%20Images_files/low_frequencies.jpg"><img src="Project%201%20Hybrid%20Images_files/high_frequencies.jpg"></center>
<p></p><p>
The high frequency image is actually zero-mean with negative values so 
it is visualized by adding 0.5. In the resulting visualization, bright 
values are positive and dark values are negative.
</p><p>
Adding the high and low frequencies together gives you the image at the 
top of this page. If you're having trouble seeing the multiple 
interpretations of the image, a useful way to visualize the effect is by
 progressively downsampling the hybrid image as is done below:
</p><p>
</p><center><img src="Project%201%20Hybrid%20Images_files/cat_hybrid_image_scales.jpg"></center>
<p></p><p>
The starter code provides a function <code>vis_hybrid_image.m</code> to save and display such visualizations.

</p><p>
<b>Potentially useful MATLAB functions</b>: <code>fspecial()</code> and the operators in the <a href="https://cs.brown.edu/courses/csci1430/2017_Spring/docs/matlab-tutorial/">MATLAB tutorial</a> which make it efficient to cut out image subwindows and do the convolution (dot product) between them. <code>padarray()</code>. 
<br>
<b>Forbidden functions</b> you can use for testing, but not in your final code: <code>imfilter()</code>, <code>filter2()</code>, <code>conv2()</code>, <code>nlfilter()</code>, <code>colfilt()</code>.
</p><br>

<h2> Bells &amp; Whistles (Extra Points)</h2>
<p>
For later projects there will be more concrete extra credit suggestions.
 It is possible to get extra credit for this project, as well, if you 
come up with some clever extensions which impress the TAs. For instance,
 how fast is your approach, and is there a faster way to perform the 
computation? If so, when is it faster, and when is it not?
</p>
<br>

<h2>Writeup</h2>
<p>
For this project, and all other projects, you must complete a project 
report in HTML. We provide you with a placeholder .html document which 
you can edit. In the report you will answer three questions (below), 
describe your algorithm, and describe any decisions you made to write 
your algorithm in a particular way. Then, you will show and discuss the 
results of your algorithm. In the case of this project, show the results
 of your filtering algorithm (the test script saves such images already)
 and show some of the intermediate images in the hybrid image pipeline 
(e.g. the low and high frequency images, which the starter code already 
saves for you). Also, discuss anything extra you did. Feel free to add 
any other information you feel is relevant.
</p>
<p>
<em>We will be conducting anonymous TA grading, so please don't include your name or ID in your writeup.</em>
</p>

<h3>Writeup Questions</h3>
Please answer these in your write-up.
<ol>
  <li>Explicitly describe image filtering (the input, the transformation, and the output) and why it is useful for computer vision.</li>
  <li>What is the difference between a high pass filter and a low pass 
filter in how they are constructed, and what they do to the image?</li>
  <li>How does the Fourier transform relate to image filtering?</li>
</ol>
<br>

<h2> Rubric </h2>
<ul> 
   <li> +50 pts: Working implementation of image filtering in <code>my_imfilter.m</code></li>
   <li> +30 pts: Working hybrid image generation</li>
   <li> +20 pts: Writeup with three questions answered, and several examples of hybrid images</li>
   <li> +10 pts: Extra credit (up to ten points) </li>
   <li> -5*n pts: Lose 5 points for every time (after the first) you do not follow the instructions for the hand in format</li>
</ul>
<br>

<h2> Web-Publishing Results </h2>
<p>
<!--All the results for each project will be put on the course website so that the students can see each other's results.-->
The professor and TAs will select impressive projects to be highlighed 
in class and on the course website. If you do not want your results 
published to the web, you can choose to opt out. If you want to opt out,
 then please email the instructor.
</p>
<br>

<h2> Hand-in process</h2>
<p>
<em>We will be conducting anonymous TA grading, so please don't include your name or ID in your writeup.</em>
</p>
<p>
The hand-in structure is very important as you will lose points if you 
do not follow instructions. Every time after the first that you do not 
follow instructions, you will lose 5 points. The folder you hand in must
 contain the following:
</p>
<ul>
    <li> README - text file containing anything about the project that 
you want to tell the TAs but not anyone else (e.g., if your project is 
selected to be published on the webpage).</li>
    <li> code/ - directory containing all your code for this assignment.</li>
    <li> html/ - directory containing all your html report for this 
assignment (including images). Only this folder will be published to the
 course web page, so your webpage cannot contain pointers to images in 
other folders of your handin.</li>
    <li> html/index.html - home page for your results </li>
</ul>
<p>
Hand in your project through using the `cs1430_handin' script. Navigate 
to your completed homework directory structure (e.g., ~/CS1430/Proj1/), 
then call cs1430_handin from the terminal. Choose proj1. You should 
receive an email confirming your handin.
</p>


<h2>Credits</h2>
<p>Assignment developed by James Hays based on a similar project by Derek Hoiem.

</p></div>




</body></html>